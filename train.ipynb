{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c351ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from transformer import Transformer\n",
    "from collections import defaultdict\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34fbf53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './data/tiny-shakespeare.txt'\n",
    "lines = []\n",
    "with open(fname, 'r') as f:\n",
    "    while (line := f.readline()):\n",
    "        lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc1f1a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "print(len(lines))\n",
    "print(sum(l.endswith('\\n') for l in lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2462274c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n', 'B', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e']\n"
     ]
    }
   ],
   "source": [
    "data = \"\".join(lines)\n",
    "print([c for c in data[:30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f007377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes = bytearray(data, 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f19aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self) -> None:\n",
    "        self.children = {}\n",
    "        self.is_end = False\n",
    "        self.tok = -1\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self) -> None:\n",
    "        self.root = TrieNode()\n",
    "    \n",
    "    def insert(self, bytes: bytearray, tok: int) -> None:\n",
    "        dummy = self.root\n",
    "        for b in bytes:\n",
    "            if b not in dummy.children:\n",
    "                dummy.children[b] = TrieNode()\n",
    "            dummy = dummy.children[b]\n",
    "        dummy.is_end = True\n",
    "        dummy.tok = tok\n",
    "\n",
    "class BytePairEncoder:\n",
    "    def __init__(self) -> None:\n",
    "        self.trie = Trie()\n",
    "        self.bpe = {}\n",
    "        self.tokens = {}\n",
    "    \n",
    "    def encode(self, bytes: bytearray) -> List[int]:\n",
    "        # current 2n\n",
    "        tokens = []\n",
    "        cur = self.trie.root\n",
    "        cur_tok = -1\n",
    "        idx = -1\n",
    "\n",
    "        i = 0\n",
    "        n = len(bytes)\n",
    "\n",
    "        while i < n:\n",
    "            if cur.is_end:\n",
    "                cur_tok = cur.tok\n",
    "                idx = i\n",
    "\n",
    "            if bytes[i] not in cur.children:\n",
    "                tokens.append(cur_tok)\n",
    "                cur = self.trie.root\n",
    "                cur_tok = -1\n",
    "                i = idx\n",
    "            else:\n",
    "                cur = cur.children[bytes[i]]\n",
    "                i += 1\n",
    "    \n",
    "        return tokens\n",
    "\n",
    "    def decode(self, tokens: List[int]) -> str:\n",
    "        bytes = bytearray([b for tok in tokens for b in self.bytes[tok]])\n",
    "        return str(bytes, encoding='utf8')\n",
    "\n",
    "    def train(self, bytes: str, vocab_size: int) -> None:\n",
    "        # TODO:\n",
    "        #   add special tokens\n",
    "        #   EOS/BOS not necessary for one doc\n",
    "        #   bug right now\n",
    "        #   how to place BOS and EOS?\n",
    "        self.trie = Trie()\n",
    "        self.tokens = {}\n",
    "        self.bytes = {}\n",
    "        for b in range(256):\n",
    "            self.bytes[b] = [b]\n",
    "            self.tokens[(b)] = b\n",
    "            self.trie.insert([b], b)\n",
    "        # for special_tok in [\"<EOS>\", \"<BOS>\", \"<PAD>\"]:\n",
    "        #    tok = len(self.tokens)\n",
    "        #    b = bytearray(special_tok, 'utf8')\n",
    "        #    self.bytes[tok] = b\n",
    "        #    self.tokens[tuple(b)] = tok\n",
    "        if vocab_size < 256: raise ValueError(\"vocabulary size < 259\")\n",
    "\n",
    "        for _ in range(vocab_size - 256):\n",
    "            freq = defaultdict(int)\n",
    "            maxpair = None\n",
    "\n",
    "            tokens = self.encode(bytes)\n",
    "            n = len(tokens)\n",
    "            for i in range(n - 1):\n",
    "                tok1, tok2 = tokens[i], tokens[i + 1]\n",
    "                freq[(tok1, tok2)] += 1\n",
    "                if freq[(tok1, tok2)] > freq[maxpair]:\n",
    "                    maxpair = (tok1, tok2)\n",
    "            tok_bytes = self.bytes[maxpair[0]] + self.bytes[maxpair[1]]\n",
    "\n",
    "            tok = len(self.tokens)\n",
    "            self.trie.insert(tok_bytes, tok)\n",
    "            self.bytes[tok] = tok_bytes\n",
    "            self.tokens[tuple(tok_bytes)] = tok\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4018dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BytePairEncoder()\n",
    "tokenizer.train(bytes, 280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0491fae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "1115392\n",
      ". n\n"
     ]
    }
   ],
   "source": [
    "toks = tokenizer.encode(bytes)\n",
    "decode = tokenizer.decode(toks)\n",
    "print(len(data))\n",
    "print(len(decode))\n",
    "print(data[-2], decode[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0dd7a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data, trie):\n",
    "    # 2 * n\n",
    "    tokens = []\n",
    "    cur = trie.root\n",
    "    cur_tok = \"\"\n",
    "    idx = -1\n",
    "\n",
    "    i = 0\n",
    "    n = len(data)\n",
    "\n",
    "    while i < n:\n",
    "        if cur.is_end:\n",
    "            cur_tok = cur.s\n",
    "            idx = i\n",
    "\n",
    "        if data[i] not in cur.children:\n",
    "            tokens.append(cur_tok)\n",
    "            cur = trie.root\n",
    "            i = idx\n",
    "        else:\n",
    "            cur = cur.children[data[i]]\n",
    "            i += 1\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8dd475aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F': 0, 'i': 1, 'r': 2, 's': 3, 't': 4, ' ': 5, 'C': 6, 'z': 7, 'e': 8, 'n': 9, ':': 10, '\\n': 11, 'B': 12, 'f': 13, 'o': 14, 'w': 15, 'p': 16, 'c': 17, 'd': 18, 'a': 19, 'y': 20, 'u': 21, 'h': 22, ',': 23, 'm': 24, 'k': 25, '.': 26, 'A': 27, 'l': 28, 'S': 29, 'Y': 30, 'v': 31, '?': 32, 'R': 33, 'M': 34, 'W': 35, \"'\": 36, 'L': 37, 'I': 38, 'N': 39, 'g': 40, ';': 41, 'b': 42, '!': 43, 'O': 44, 'j': 45, 'V': 46, '-': 47, 'T': 48, 'H': 49, 'E': 50, 'U': 51, 'D': 52, 'P': 53, 'q': 54, 'x': 55, 'J': 56, 'G': 57, 'K': 58, 'Q': 59, '&': 60, 'Z': 61, 'X': 62, '3': 63, '$': 64}\n",
      "({'F': 0, 'i': 1, 'r': 2, 's': 3, 't': 4, ' ': 5, 'C': 6, 'z': 7, 'e': 8, 'n': 9, ':': 10, '\\n': 11, 'B': 12, 'f': 13, 'o': 14, 'w': 15, 'p': 16, 'c': 17, 'd': 18, 'a': 19, 'y': 20, 'u': 21, 'h': 22, ',': 23, 'm': 24, 'k': 25, '.': 26, 'A': 27, 'l': 28, 'S': 29, 'Y': 30, 'v': 31, '?': 32, 'R': 33, 'M': 34, 'W': 35, \"'\": 36, 'L': 37, 'I': 38, 'N': 39, 'g': 40, ';': 41, 'b': 42, '!': 43, 'O': 44, 'j': 45, 'V': 46, '-': 47, 'T': 48, 'H': 49, 'E': 50, 'U': 51, 'D': 52, 'P': 53, 'q': 54, 'x': 55, 'J': 56, 'G': 57, 'K': 58, 'Q': 59, '&': 60, 'Z': 61, 'X': 62, '3': 63, '$': 64, 'e ': 65, 'th': 66, 't ': 67, 's ': 68, 'd ': 69, ', ': 70, 'ou': 71, 'er': 72, 'in': 73, 'y ': 74, 'an': 75, ':\\n': 76, 'or': 77, 'o ': 78, 'en': 79, '\\n\\n': 80, 'ar': 81, ' th': 82, 'on': 83, 'll': 84, 'ha': 85, ',\\n': 86, '.\\n\\n': 87, 'is ': 88, 'es': 89, 'you': 90, ' s': 91, 'to ': 92, ' m': 93, 'ow': 94, ' w': 95, 'ea': 96, 'and ': 97, 'of': 98, 'ing': 99, ' h': 100, 'om': 101, ' a': 102, 'nd ': 103, 'st': 104, ' b': 105, 'the ': 106, 'no': 107, 'ir': 108, 'for': 109, 've ': 110, 'ch': 111, 'e, ': 112, ' the ': 113, 'ith': 114, 'li': 115, 'se': 116, 'Th': 117, 'at ': 118, 're': 119, 'at': 120, ' d': 121, 'im': 122, 'it': 123, 'ear': 124, ' you': 125, 'oo': 126, 'gh': 127, ' c': 128, 'ee': 129, ' I': 130, ' p': 131, 'our': 132, 'And ': 133, \"'s \": 134, 'ill': 135, 'not ': 136, 'ri': 137, ' f': 138, 'her': 139, ';\\n': 140, '.\\n': 141, 'le': 142, 'my ': 143, ' t': 144, 'is': 145, 'ra': 146, 'ut ': 147, ' of': 148, 'ld ': 149, 'ed ': 150, ' to ': 151, 'O:\\n': 152, 'la': 153, 'd, ': 154, 'ro': 155, 'un': 156, 'EN': 157, 'ke ': 158, ' g': 159, 'y, ': 160, 'IN': 161, ' and ': 162, '?\\n\\n': 163, 'ell': 164, 'ur': 165, 'as ': 166, 'S:\\n': 167, 'e\\n': 168, 'ther': 169, 'ter': 170, ' ha': 171, 'sh': 172, 'all': 173, 'al': 174, 'ver': 175, 'with': 176, 'em': 177, 'AR': 178, 'ng': 179, 's, ': 180, 'ce ': 181, 'that ': 182, ' in': 183, 'lo': 184, 'ck': 185, ' my ': 186, 'am': 187, 'now': 188, 'ay ': 189, \"'d \": 190, 'ent': 191, 'IO:\\n': 192, 'ce': 193, 'Wh': 194, '. ': 195, 'ere ': 196, 'ould ': 197, 'ly ': 198, 'ed': 199}, {0: 'F', 1: 'i', 2: 'r', 3: 's', 4: 't', 5: ' ', 6: 'C', 7: 'z', 8: 'e', 9: 'n', 10: ':', 11: '\\n', 12: 'B', 13: 'f', 14: 'o', 15: 'w', 16: 'p', 17: 'c', 18: 'd', 19: 'a', 20: 'y', 21: 'u', 22: 'h', 23: ',', 24: 'm', 25: 'k', 26: '.', 27: 'A', 28: 'l', 29: 'S', 30: 'Y', 31: 'v', 32: '?', 33: 'R', 34: 'M', 35: 'W', 36: \"'\", 37: 'L', 38: 'I', 39: 'N', 40: 'g', 41: ';', 42: 'b', 43: '!', 44: 'O', 45: 'j', 46: 'V', 47: '-', 48: 'T', 49: 'H', 50: 'E', 51: 'U', 52: 'D', 53: 'P', 54: 'q', 55: 'x', 56: 'J', 57: 'G', 58: 'K', 59: 'Q', 60: '&', 61: 'Z', 62: 'X', 63: '3', 64: '$', 65: 'e ', 66: 'th', 67: 't ', 68: 's ', 69: 'd ', 70: ', ', 71: 'ou', 72: 'er', 73: 'in', 74: 'y ', 75: 'an', 76: ':\\n', 77: 'or', 78: 'o ', 79: 'en', 80: '\\n\\n', 81: 'ar', 82: ' th', 83: 'on', 84: 'll', 85: 'ha', 86: ',\\n', 87: '.\\n\\n', 88: 'is ', 89: 'es', 90: 'you', 91: ' s', 92: 'to ', 93: ' m', 94: 'ow', 95: ' w', 96: 'ea', 97: 'and ', 98: 'of', 99: 'ing', 100: ' h', 101: 'om', 102: ' a', 103: 'nd ', 104: 'st', 105: ' b', 106: 'the ', 107: 'no', 108: 'ir', 109: 'for', 110: 've ', 111: 'ch', 112: 'e, ', 113: ' the ', 114: 'ith', 115: 'li', 116: 'se', 117: 'Th', 118: 'at ', 119: 're', 120: 'at', 121: ' d', 122: 'im', 123: 'it', 124: 'ear', 125: ' you', 126: 'oo', 127: 'gh', 128: ' c', 129: 'ee', 130: ' I', 131: ' p', 132: 'our', 133: 'And ', 134: \"'s \", 135: 'ill', 136: 'not ', 137: 'ri', 138: ' f', 139: 'her', 140: ';\\n', 141: '.\\n', 142: 'le', 143: 'my ', 144: ' t', 145: 'is', 146: 'ra', 147: 'ut ', 148: ' of', 149: 'ld ', 150: 'ed ', 151: ' to ', 152: 'O:\\n', 153: 'la', 154: 'd, ', 155: 'ro', 156: 'un', 157: 'EN', 158: 'ke ', 159: ' g', 160: 'y, ', 161: 'IN', 162: ' and ', 163: '?\\n\\n', 164: 'ell', 165: 'ur', 166: 'as ', 167: 'S:\\n', 168: 'e\\n', 169: 'ther', 170: 'ter', 171: ' ha', 172: 'sh', 173: 'all', 174: 'al', 175: 'ver', 176: 'with', 177: 'em', 178: 'AR', 179: 'ng', 180: 's, ', 181: 'ce ', 182: 'that ', 183: ' in', 184: 'lo', 185: 'ck', 186: ' my ', 187: 'am', 188: 'now', 189: 'ay ', 190: \"'d \", 191: 'ent', 192: 'IO:\\n', 193: 'ce', 194: 'Wh', 195: '. ', 196: 'ere ', 197: 'ould ', 198: 'ly ', 199: 'ed'})\n"
     ]
    }
   ],
   "source": [
    "def bpe(data, size):\n",
    "    trie = Trie()\n",
    "    bps = {}\n",
    "    toks = {}\n",
    "    for c in data:\n",
    "        if c not in bps:\n",
    "            toks[len(bps)] = c\n",
    "            bps[c] = len(bps)\n",
    "    if len(bps) > size: raise ValueError(\"vocabulary size < current size\")\n",
    "    for c in bps:\n",
    "        trie.insert(c)\n",
    "\n",
    "    for _ in range(size - len(bps)):\n",
    "        tokens = encode(data, trie)\n",
    "        freq = defaultdict(int)\n",
    "        n = len(tokens)\n",
    "        maxpair = None\n",
    "        for i in range(n - 1):\n",
    "            a, b = bps[tokens[i]], bps[tokens[i + 1]]\n",
    "            freq[(a, b)] += 1\n",
    "            if freq[(a, b)] > freq[maxpair]:\n",
    "                maxpair = (a, b)\n",
    "        tok = toks[maxpair[0]] + toks[maxpair[1]]\n",
    "        trie.insert(tok)\n",
    "        toks[len(bps)] = tok\n",
    "        bps[tok] = len(bps)\n",
    "    return bps, toks\n",
    "\n",
    "print(bpe(data, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 1024        # num dimensions = dim(model)\n",
    "L = 1           # num layers\n",
    "H = 8           # num heads\n",
    "MAXT = 4098     # max tokens\n",
    "V = 4098        # vocab size\n",
    "d_ff = 2048     # dim(FFN hidden layers)\n",
    "p_drop = 0.1    # dropout prob\n",
    "\n",
    "transformer = Transformer(d, L, H, MAXT, V, d_ff, p_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ba3f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 4098])\n",
      "tensor([[[ 53.1798,  38.1477, -28.7207,  ..., -16.9216,   2.8838,  -1.6856],\n",
      "         [ 27.5028, -17.9487,  30.4112,  ...,  83.4197,  31.8329, -35.6247],\n",
      "         [ 44.7758,  42.3246, -23.0053,  ..., -47.0368, -24.6917,   1.8160],\n",
      "         ...,\n",
      "         [-17.7791,  95.5564,  21.2843,  ...,  38.1742,   9.4863,  15.7194],\n",
      "         [ -1.5760, -93.9202, -34.0709,  ...,  75.0702,  12.7765, -14.5807],\n",
      "         [-25.9921,  12.1569, -30.9109,  ...,  25.1669,  46.5577,   5.1974]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.randint(V, (1, 256))\n",
    "out = transformer(X)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053c87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ashton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
